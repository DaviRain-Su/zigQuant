# AI æ¨¡å— - æµ‹è¯•æ–‡æ¡£

> æµ‹è¯•è¦†ç›–å’Œæ€§èƒ½åŸºå‡†

**æ¨¡å—è·¯å¾„**: `src/ai/`
**ç‰ˆæœ¬**: v0.9.0
**æœ€åæ›´æ–°**: 2025-12-28

---

## æµ‹è¯•è¦†ç›–ç‡

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| **ä»£ç è¦†ç›–ç‡** | ç›®æ ‡ > 85% |
| **æµ‹è¯•ç”¨ä¾‹æ•°** | 30+ |
| **æ€§èƒ½åŸºå‡†** | å»¶è¿Ÿè¿½è¸ª |

---

## æµ‹è¯•åˆ†ç±»

### 1. å•å…ƒæµ‹è¯•

#### ç±»å‹å®šä¹‰æµ‹è¯•

```zig
test "AIAdvice.toScore returns correct values" {
    const test_cases = [_]struct { action: AIAdvice.Action, expected: f64 }{
        .{ .action = .strong_buy, .expected = 1.0 },
        .{ .action = .buy, .expected = 0.75 },
        .{ .action = .hold, .expected = 0.5 },
        .{ .action = .sell, .expected = 0.25 },
        .{ .action = .strong_sell, .expected = 0.0 },
    };

    for (test_cases) |tc| {
        const advice = AIAdvice{
            .action = tc.action,
            .confidence = 0.8,
            .reasoning = "test",
            .timestamp = 0,
        };
        try std.testing.expectEqual(tc.expected, advice.toScore());
    }
}

test "AIConfig default values" {
    const config = AIConfig{
        .provider = .openai,
        .model_id = "gpt-4o",
        .api_key = "test-key",
    };

    try std.testing.expectEqual(@as(u32, 1024), config.max_tokens);
    try std.testing.expectApproxEqAbs(@as(f32, 0.3), config.temperature, 0.001);
    try std.testing.expectEqual(@as(u32, 30000), config.timeout_ms);
}

test "AIProvider enum values" {
    try std.testing.expectEqual(@as(usize, 4), @typeInfo(AIProvider).Enum.fields.len);
}
```

---

#### PromptBuilder æµ‹è¯•

```zig
test "PromptBuilder.init and deinit" {
    var builder = PromptBuilder.init(std.testing.allocator);
    defer builder.deinit();

    try std.testing.expect(builder.buffer.items.len == 0);
}

test "PromptBuilder.buildMarketAnalysisPrompt" {
    var builder = PromptBuilder.init(std.testing.allocator);
    defer builder.deinit();

    const ctx = MarketContext{
        .pair = .{ .base = "BTC", .quote = "USDT" },
        .current_price = Decimal.fromFloat(45000.0),
        .price_change_24h = 0.025,
        .indicators = &.{
            .{ .name = "RSI", .value = 35.5, .interpretation = "approaching oversold" },
        },
        .recent_candles = &.{},
        .position = null,
    };

    const prompt = try builder.buildMarketAnalysisPrompt(ctx);

    // éªŒè¯ prompt åŒ…å«å¿…è¦å†…å®¹
    try std.testing.expect(std.mem.indexOf(u8, prompt, "BTC/USDT") != null);
    try std.testing.expect(std.mem.indexOf(u8, prompt, "45000") != null);
    try std.testing.expect(std.mem.indexOf(u8, prompt, "RSI") != null);
    try std.testing.expect(std.mem.indexOf(u8, prompt, "35.5") != null);
    try std.testing.expect(std.mem.indexOf(u8, prompt, "trading recommendation") != null);
}

test "PromptBuilder.buildMarketAnalysisPrompt with position" {
    var builder = PromptBuilder.init(std.testing.allocator);
    defer builder.deinit();

    const ctx = MarketContext{
        .pair = .{ .base = "ETH", .quote = "USDT" },
        .current_price = Decimal.fromFloat(2500.0),
        .price_change_24h = -0.015,
        .indicators = &.{},
        .recent_candles = &.{},
        .position = Position{
            .side = .long,
            .entry_price = Decimal.fromFloat(2400.0),
            .unrealized_pnl_pct = 0.0417,
        },
    };

    const prompt = try builder.buildMarketAnalysisPrompt(ctx);

    // éªŒè¯åŒ…å«ä»“ä½ä¿¡æ¯
    try std.testing.expect(std.mem.indexOf(u8, prompt, "Current Position") != null);
    try std.testing.expect(std.mem.indexOf(u8, prompt, "long") != null);
}

test "PromptBuilder.getAdviceSchema returns valid JSON" {
    const schema = PromptBuilder.getAdviceSchema();

    // éªŒè¯å¯è§£æä¸º JSON
    const parsed = try std.json.parseFromSlice(
        std.json.Value,
        std.testing.allocator,
        schema,
        .{},
    );
    defer parsed.deinit();

    // éªŒè¯ schema ç»“æ„
    try std.testing.expect(parsed.value.object.get("type") != null);
    try std.testing.expect(parsed.value.object.get("properties") != null);
    try std.testing.expect(parsed.value.object.get("required") != null);
}
```

---

#### ILLMClient æ¥å£æµ‹è¯•

```zig
test "ILLMClient interface conformance" {
    // éªŒè¯ VTable ç»“æ„
    const vtable_info = @typeInfo(ILLMClient.VTable);
    try std.testing.expectEqual(@as(usize, 5), vtable_info.Struct.fields.len);

    // éªŒè¯å­—æ®µå
    const expected_fields = [_][]const u8{
        "generateText",
        "generateObject",
        "getModel",
        "isConnected",
        "deinit",
    };

    for (expected_fields) |field_name| {
        var found = false;
        for (vtable_info.Struct.fields) |field| {
            if (std.mem.eql(u8, field.name, field_name)) {
                found = true;
                break;
            }
        }
        try std.testing.expect(found);
    }
}
```

---

### 2. Mock æµ‹è¯•

#### MockLLMClient å®ç°

```zig
pub const MockLLMClient = struct {
    response: []const u8,
    call_count: u32 = 0,
    should_fail: bool = false,
    fail_error: anyerror = error.ApiError,

    pub fn init(response: []const u8) MockLLMClient {
        return .{ .response = response };
    }

    pub fn initFailing(err: anyerror) MockLLMClient {
        return .{
            .response = "",
            .should_fail = true,
            .fail_error = err,
        };
    }

    pub fn toInterface(self: *MockLLMClient) ILLMClient {
        return .{
            .ptr = self,
            .vtable = &mock_vtable,
        };
    }

    fn generateTextImpl(ptr: *anyopaque, _: []const u8) anyerror![]const u8 {
        const self: *MockLLMClient = @ptrCast(@alignCast(ptr));
        self.call_count += 1;

        if (self.should_fail) {
            return self.fail_error;
        }
        return self.response;
    }

    fn generateObjectImpl(ptr: *anyopaque, _: []const u8, _: []const u8) anyerror![]const u8 {
        const self: *MockLLMClient = @ptrCast(@alignCast(ptr));
        self.call_count += 1;

        if (self.should_fail) {
            return self.fail_error;
        }
        return self.response;
    }

    fn getModelImpl(_: *anyopaque) AIModel {
        return .{ .provider = .custom, .model_id = "mock-model" };
    }

    fn isConnectedImpl(_: *anyopaque) bool {
        return true;
    }

    fn deinitImpl(_: *anyopaque) void {}

    const mock_vtable = ILLMClient.VTable{
        .generateText = generateTextImpl,
        .generateObject = generateObjectImpl,
        .getModel = getModelImpl,
        .isConnected = isConnectedImpl,
        .deinit = deinitImpl,
    };
};
```

#### Mock æµ‹è¯•ç”¨ä¾‹

```zig
test "MockLLMClient basic usage" {
    var mock = MockLLMClient.init("Hello, World!");
    const client = mock.toInterface();

    const response = try client.generateText("test prompt");
    try std.testing.expectEqualStrings("Hello, World!", response);
    try std.testing.expectEqual(@as(u32, 1), mock.call_count);
}

test "MockLLMClient failure simulation" {
    var mock = MockLLMClient.initFailing(error.Timeout);
    const client = mock.toInterface();

    const result = client.generateText("test prompt");
    try std.testing.expectError(error.Timeout, result);
}

test "AIAdvisor with MockLLMClient" {
    const mock_response =
        \\{"action": "buy", "confidence": 0.85, "reasoning": "Strong bullish momentum detected"}
    ;

    var mock = MockLLMClient.init(mock_response);
    var advisor = AIAdvisor.init(std.testing.allocator, mock.toInterface(), .{});
    defer advisor.deinit();

    const ctx = MarketContext{
        .pair = .{ .base = "BTC", .quote = "USDT" },
        .current_price = Decimal.fromFloat(45000.0),
        .price_change_24h = 0.025,
        .indicators = &.{},
        .recent_candles = &.{},
        .position = null,
    };

    const advice = try advisor.getAdvice(ctx);

    try std.testing.expectEqual(AIAdvice.Action.buy, advice.action);
    try std.testing.expectApproxEqAbs(@as(f64, 0.85), advice.confidence, 0.001);
    try std.testing.expectEqualStrings("Strong bullish momentum detected", advice.reasoning);
    try std.testing.expectEqual(@as(u32, 1), mock.call_count);
}

test "AIAdvisor stats tracking" {
    const mock_response =
        \\{"action": "hold", "confidence": 0.6, "reasoning": "Neutral market conditions"}
    ;

    var mock = MockLLMClient.init(mock_response);
    var advisor = AIAdvisor.init(std.testing.allocator, mock.toInterface(), .{});
    defer advisor.deinit();

    const ctx = createTestContext();

    // å¤šæ¬¡è°ƒç”¨
    _ = try advisor.getAdvice(ctx);
    _ = try advisor.getAdvice(ctx);
    _ = try advisor.getAdvice(ctx);

    const stats = advisor.getStats();
    try std.testing.expectEqual(@as(u64, 3), stats.total_requests);
    try std.testing.expectEqual(@as(u64, 3), stats.successful_requests);
    try std.testing.expectApproxEqAbs(@as(f64, 1.0), stats.success_rate, 0.001);
}
```

---

### 3. é›†æˆæµ‹è¯•

#### HybridAIStrategy æµ‹è¯•

```zig
test "HybridAIStrategy creation" {
    const strategy = try HybridAIStrategy.create(std.testing.allocator, .{
        .pair = .{ .base = "BTC", .quote = "USDT" },
        .timeframe = .h1,
        .ai_weight = 0.4,
        .technical_weight = 0.6,
        .ai_config = createTestAIConfig(),
    });
    defer strategy.destroy();

    try std.testing.expect(strategy.initialized == false); // æœªåˆå§‹åŒ–
}

test "HybridAIStrategy invalid weights" {
    const result = HybridAIStrategy.create(std.testing.allocator, .{
        .pair = .{ .base = "BTC", .quote = "USDT" },
        .timeframe = .h1,
        .ai_weight = 0.5,
        .technical_weight = 0.6, // æ€»å’Œ != 1.0
        .ai_config = createTestAIConfig(),
    });

    try std.testing.expectError(error.InvalidWeights, result);
}

test "HybridAIStrategy toStrategy interface" {
    const strategy = try createTestHybridStrategy(std.testing.allocator);
    defer strategy.destroy();

    const iface = strategy.toStrategy();

    // éªŒè¯æ¥å£æœ‰æ•ˆ
    try std.testing.expect(iface.vtable != null);
    try std.testing.expect(iface.ptr != null);
}

test "HybridAIStrategy signal generation with mock" {
    // ä½¿ç”¨ Mock LLM æµ‹è¯•ä¿¡å·ç”Ÿæˆ
    var strategy = try createTestHybridStrategyWithMock(std.testing.allocator);
    defer strategy.destroy();

    const candles = try createTestCandles(std.testing.allocator, 100);
    defer candles.deinit();

    // åˆå§‹åŒ–ç­–ç•¥
    try strategy.toStrategy().init(&candles);
    defer strategy.toStrategy().deinit();

    // ç”Ÿæˆä¿¡å·
    const signal = strategy.toStrategy().generateEntrySignal(&candles, 50);

    if (signal) |s| {
        try std.testing.expect(s.strength >= 0.0 and s.strength <= 1.0);
        try std.testing.expect(s.pair.base.len > 0);
    }
}
```

---

### 4. å†…å­˜æµ‹è¯•

```zig
test "LLMClient no memory leaks" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer {
        const leaked = gpa.deinit();
        if (leaked == .leak) @panic("Memory leak detected in LLMClient!");
    }
    const allocator = gpa.allocator();

    // æµ‹è¯•å¤šæ¬¡åˆ›å»ºå’Œé”€æ¯
    for (0..10) |_| {
        const client = try LLMClient.init(allocator, createTestAIConfig());
        client.deinit();
    }
}

test "AIAdvisor no memory leaks" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer {
        const leaked = gpa.deinit();
        if (leaked == .leak) @panic("Memory leak detected in AIAdvisor!");
    }
    const allocator = gpa.allocator();

    var mock = MockLLMClient.init("{}");
    var advisor = AIAdvisor.init(allocator, mock.toInterface(), .{});
    advisor.deinit();
}

test "PromptBuilder no memory leaks" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer {
        const leaked = gpa.deinit();
        if (leaked == .leak) @panic("Memory leak detected in PromptBuilder!");
    }
    const allocator = gpa.allocator();

    var builder = PromptBuilder.init(allocator);

    // å¤šæ¬¡æ„å»º prompt
    for (0..10) |_| {
        _ = try builder.buildMarketAnalysisPrompt(createTestContext());
    }

    builder.deinit();
}

test "HybridAIStrategy no memory leaks" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer {
        const leaked = gpa.deinit();
        if (leaked == .leak) @panic("Memory leak detected in HybridAIStrategy!");
    }
    const allocator = gpa.allocator();

    const strategy = try createTestHybridStrategyWithMock(allocator);
    strategy.destroy();
}
```

---

## æ€§èƒ½åŸºå‡†

### åŸºå‡†æµ‹è¯•

```zig
test "PromptBuilder performance" {
    var builder = PromptBuilder.init(std.testing.allocator);
    defer builder.deinit();

    const ctx = createTestContext();
    const iterations: u32 = 1000;

    const start = std.time.nanoTimestamp();
    for (0..iterations) |_| {
        _ = try builder.buildMarketAnalysisPrompt(ctx);
    }
    const elapsed = std.time.nanoTimestamp() - start;

    const ns_per_op = @divFloor(elapsed, iterations);
    std.debug.print("PromptBuilder: {} ns/op\n", .{ns_per_op});

    // éªŒè¯æ€§èƒ½ (< 1ms per operation)
    try std.testing.expect(ns_per_op < 1_000_000);
}

test "AIAdvice.toScore performance" {
    const iterations: u32 = 100_000;

    const start = std.time.nanoTimestamp();
    for (0..iterations) |_| {
        const advice = AIAdvice{
            .action = .buy,
            .confidence = 0.8,
            .reasoning = "test",
            .timestamp = 0,
        };
        _ = advice.toScore();
    }
    const elapsed = std.time.nanoTimestamp() - start;

    const ns_per_op = @divFloor(elapsed, iterations);
    std.debug.print("AIAdvice.toScore: {} ns/op\n", .{ns_per_op});

    // éªŒè¯æ€§èƒ½ (< 100ns per operation)
    try std.testing.expect(ns_per_op < 100);
}
```

### åŸºå‡†ç»“æœ

| æ“ä½œ | æ€§èƒ½ | ç›®æ ‡ |
|------|------|------|
| `PromptBuilder.buildMarketAnalysisPrompt` | < 1ms | < 5ms |
| `AIAdvice.toScore` | < 100ns | < 1us |
| `MockLLMClient.generateText` | < 1us | < 10us |
| JSON è§£æ (AIAdvice) | < 100us | < 1ms |

---

## è¿è¡Œæµ‹è¯•

### è¿è¡Œæ‰€æœ‰ AI æ¨¡å—æµ‹è¯•

```bash
zig test src/ai/mod.zig
```

### è¿è¡Œç‰¹å®šæ–‡ä»¶æµ‹è¯•

```bash
# ç±»å‹æµ‹è¯•
zig test src/ai/types.zig

# æ¥å£æµ‹è¯•
zig test src/ai/interfaces.zig

# å®¢æˆ·ç«¯æµ‹è¯•
zig test src/ai/client.zig

# Advisor æµ‹è¯•
zig test src/ai/advisor.zig

# PromptBuilder æµ‹è¯•
zig test src/ai/prompt_builder.zig
```

### è¿è¡Œé›†æˆæµ‹è¯•

```bash
# HybridAIStrategy æµ‹è¯•
zig test src/strategy/builtin/hybrid_ai.zig
```

### è¿è¡Œæ€§èƒ½åŸºå‡†

```bash
zig test --release-safe src/ai/mod.zig
```

---

## æµ‹è¯•åœºæ™¯

### âœ… å·²è¦†ç›–

- [x] AIAdvice.toScore æ­£ç¡®æ€§
- [x] AIConfig é»˜è®¤å€¼
- [x] AIProvider æšä¸¾å®Œæ•´æ€§
- [x] PromptBuilder åˆå§‹åŒ–/é”€æ¯
- [x] PromptBuilder å¸‚åœºåˆ†æ Prompt ç”Ÿæˆ
- [x] PromptBuilder å¸¦ä»“ä½ä¿¡æ¯ Prompt
- [x] PromptBuilder JSON Schema æœ‰æ•ˆæ€§
- [x] ILLMClient æ¥å£ä¸€è‡´æ€§
- [x] MockLLMClient åŸºç¡€åŠŸèƒ½
- [x] MockLLMClient å¤±è´¥æ¨¡æ‹Ÿ
- [x] AIAdvisor ä¸ Mock é›†æˆ
- [x] AIAdvisor ç»Ÿè®¡è¿½è¸ª
- [x] HybridAIStrategy åˆ›å»º
- [x] HybridAIStrategy æƒé‡éªŒè¯
- [x] HybridAIStrategy æ¥å£è½¬æ¢
- [x] å†…å­˜æ³„æ¼æ£€æµ‹ (æ‰€æœ‰ç»„ä»¶)

### ğŸ“‹ å¾…è¡¥å……

- [ ] LLMClient çœŸå® API æµ‹è¯• (éœ€è¦ API Key)
- [ ] HybridAIStrategy å›æµ‹é›†æˆæµ‹è¯•
- [ ] AI å¤±è´¥å›é€€æµ‹è¯•
- [ ] å¹¶å‘è¯·æ±‚æµ‹è¯•
- [ ] ç¼“å­˜ TTL æµ‹è¯•
- [ ] é‡è¯•æœºåˆ¶æµ‹è¯•
- [ ] è¶…æ—¶å¤„ç†æµ‹è¯•

---

## æµ‹è¯•å·¥å…·å‡½æ•°

```zig
fn createTestContext() MarketContext {
    return .{
        .pair = .{ .base = "BTC", .quote = "USDT" },
        .current_price = Decimal.fromFloat(45000.0),
        .price_change_24h = 0.025,
        .indicators = &.{
            .{ .name = "RSI", .value = 35.5, .interpretation = "approaching oversold" },
        },
        .recent_candles = &.{},
        .position = null,
    };
}

fn createTestAIConfig() AIConfig {
    return .{
        .provider = .anthropic,
        .model_id = "claude-sonnet-4-5",
        .api_key = "test-api-key",
        .temperature = 0.3,
    };
}

fn createTestHybridStrategyWithMock(allocator: std.mem.Allocator) !*HybridAIStrategy {
    // åˆ›å»ºå¸¦ Mock LLM çš„æµ‹è¯•ç­–ç•¥
    // ...
}

fn createTestCandles(allocator: std.mem.Allocator, count: usize) !Candles {
    // åˆ›å»ºæµ‹è¯•ç”¨ K çº¿æ•°æ®
    // ...
}
```

---

## ç›¸å…³æ–‡æ¡£

- [åŠŸèƒ½æ¦‚è§ˆ](./README.md)
- [API å‚è€ƒ](./api.md)
- [å®ç°ç»†èŠ‚](./implementation.md)
- [Bug è¿½è¸ª](./bugs.md)
- [å˜æ›´æ—¥å¿—](./changelog.md)

---

*æœ€åæ›´æ–°: 2025-12-28*
